{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n",
      "   img  steeringAng\n",
      "0    1            9\n",
      "1    2            9\n",
      "2    3            9\n",
      "3    4            9\n",
      "4    5            9\n",
      "5    6            9\n",
      "6    7            9\n",
      "7    8            9\n",
      "8    9            9\n",
      "9   10            9\n",
      "importing Jupyter notebook from Model.ipynb\n",
      "   img  steeringAng\n",
      "0    1            9\n",
      "1    2            9\n",
      "2    3            9\n",
      "3    4            9\n",
      "4    5            9\n",
      "5    6            9\n",
      "6    7            9\n",
      "7    8            9\n",
      "8    9            9\n",
      "9   10            9\n",
      "('units after conv', 512)\n",
      "('conv parameters: ', 168224)\n",
      "('fc parameters: ', 166804)\n",
      "('input', torch.Size([256, 3, 480, 640]))\n",
      "tensor([[-0.9283, -1.3190,  2.2029,  ...,  0.3183, -0.6540, -0.7787],\n",
      "        [-0.7625, -1.2429,  2.1065,  ...,  0.3452, -0.5638, -0.7715],\n",
      "        [-1.7469, -2.0672,  1.8136,  ..., -0.0621, -0.8134, -0.9749],\n",
      "        ...,\n",
      "        [-1.6539, -1.4375,  1.8011,  ..., -0.1056, -0.9806, -0.5534],\n",
      "        [-1.1725, -1.2008,  1.5482,  ...,  0.3451, -1.2943, -0.7793],\n",
      "        [-1.1880, -0.9993,  1.4728,  ...,  0.5643, -1.2566, -1.1597]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "('output', torch.Size([256, 20]))\n",
      "('using device', device(type='cpu'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "REPORT_EVERY_ITER = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Stack size', 1)\n",
      "('units after conv', 512)\n",
      "('conv parameters: ', 168224)\n",
      "('fc parameters: ', 166804)\n",
      "('Data size', 22036)\n",
      "('number of parameters: ', 335028)\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "dataset.convertTOClass()\n",
    "print(\"Stack size\", dataset.stack_size)\n",
    "# dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)\n",
    "net = ConvNet().to(device)\n",
    "\n",
    "print(\"Data size\", dataset.data_frame.size)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   img  steeringAng\n",
      "0    1            9\n",
      "1    2            9\n",
      "2    3            9\n",
      "3    4            9\n",
      "4    5            9\n",
      "5    6            9\n",
      "6    7            9\n",
      "7    8            9\n",
      "8    9            9\n",
      "9   10            9\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data_frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total training stacks', 35)\n",
      "('Total validation stacks', 9)\n"
     ]
    }
   ],
   "source": [
    "validation_split = .2\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "# spliting the dataset\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "# Training data loader # NOTE had to remove shuffle\n",
    "dataloader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=train_sampler)\n",
    "\n",
    "# Validation data loader # NOTE had to remove shuffle\n",
    "validLoader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=valid_sampler)\n",
    "\n",
    "print(\"Total training stacks\", len(dataloader))\n",
    "print(\"Total validation stacks\",len(validLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('imagesSize: ', torch.Size([256, 3, 480, 640]), 'controlsSize:', torch.Size([256, 1]))\n",
      "tensor([[ 0.1306, -0.1476,  2.7605,  ..., -0.7274, -1.7934,  0.3676],\n",
      "        [ 0.3611,  0.4607,  3.6346,  ..., -1.0026, -2.0363,  0.3889],\n",
      "        [ 0.4955,  0.1366,  3.0700,  ..., -1.2756, -1.7462,  0.1997],\n",
      "        ...,\n",
      "        [ 0.2576,  0.0906,  3.1452,  ..., -1.1252, -1.7429,  0.2163],\n",
      "        [ 0.5677,  0.3912,  3.9142,  ..., -1.0691, -3.5141, -0.7693],\n",
      "        [ 0.2896,  0.7397,  3.5749,  ..., -1.0281, -1.8536,  0.5783]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "(torch.Size([256, 20]), torch.Size([256]))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 4584 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c89077406a90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcontrols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/loss.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 4584 is out of bounds."
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss() # Changed from Mean-Squared to Cross-Entropy\n",
    "writer = SummaryWriter()\n",
    "iter_no = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        iter_no += 1\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).long()\n",
    "        print(\"imagesSize: \", images.size(), \"controlsSize:\", controls.size())\n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(images)\n",
    "        \n",
    "        controls = torch.flatten(controls)\n",
    "        print(prediction.size(), controls.size())\n",
    "        loss = criterion(prediction, controls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_no % REPORT_EVERY_ITER == 0:\n",
    "            writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "            torch.save(net.state_dict(), \"snapshots/saved_model_{}\".format(loss.item()))\n",
    "        \n",
    "        out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "        print(out.format(str(epoch),\n",
    "                        str(iter_no),\n",
    "                        round(loss.item(),5),\n",
    "                         'na', 'na'\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                        ))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Test\n",
    "iter_no = 0\n",
    "for i_batch, sampled_batch in enumerate(validLoader):\n",
    "    iter_no += 1\n",
    "    images = sampled_batch['image'].to(device).float()\n",
    "    controls = sampled_batch['control'].to(device).float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    prediction = net(images)\n",
    "    loss = criterion(prediction, controls)\n",
    "    out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "    print(out.format(str(epoch),\n",
    "                    str(iter_no),\n",
    "                    round(loss.item(),5),\n",
    "                     'na', 'na'\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                    ))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
