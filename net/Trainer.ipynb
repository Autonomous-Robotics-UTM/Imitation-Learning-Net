{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('using device', device(type='cpu'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "REPORT_EVERY_ITER = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Stack size', 1)\n",
      "('units after conv', 512)\n",
      "('conv parameters: ', 168224)\n",
      "('fc parameters: ', 164353)\n",
      "('Data size', 11018)\n",
      "('number of parameters: ', 332577)\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "print(\"Stack size\", dataset.stack_size)\n",
    "# dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)\n",
    "net = ConvNet().to(device)\n",
    "\n",
    "print(\"Data size\", dataset.data_frame.size)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "validation_split = .2\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "# Training data loader\n",
    "dataloader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=train_sampler)\n",
    "\n",
    "# Validation data loader\n",
    "validLoader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=valid_sampler)\n",
    "\n",
    "print(len(dataloader))\n",
    "print(len(validLoader))\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "#                                            sampler=train_sampler)\n",
    "# validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "#                                                 sampler=valid_sampler)\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\tLoss:0.05935\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,2\tLoss:0.04808\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,3\tLoss:0.0698\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,4\tLoss:0.0435\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,5\tLoss:0.06472\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,6\tLoss:0.05344\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,7\tLoss:0.05261\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,8\tLoss:0.04632\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,9\tLoss:0.04518\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,10\tLoss:0.05029\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,11\tLoss:0.04766\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,12\tLoss:0.05506\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,13\tLoss:0.04393\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,14\tLoss:0.05144\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,15\tLoss:0.05188\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,16\tLoss:0.05526\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,17\tLoss:0.03742\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,18\tLoss:0.04996\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,19\tLoss:0.04647\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,20\tLoss:0.04963\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,21\tLoss:0.04038\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,22\tLoss:0.04393\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,23\tLoss:0.04527\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,24\tLoss:0.04766\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,25\tLoss:0.04617\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,26\tLoss:0.03958\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,27\tLoss:0.03505\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,28\tLoss:0.04377\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,29\tLoss:0.03793\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,30\tLoss:0.04066\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,31\tLoss:0.0486\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,32\tLoss:0.05115\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,33\tLoss:0.03813\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,34\tLoss:0.04832\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,35\tLoss:0.0392\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,36\tLoss:0.04044\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,37\tLoss:0.0392\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,38\tLoss:0.03769\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,39\tLoss:0.05052\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,40\tLoss:0.04253\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,41\tLoss:0.03765\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,42\tLoss:0.0377\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,43\tLoss:0.04034\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,44\tLoss:0.03786\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,45\tLoss:0.03185\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,46\tLoss:0.03194\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,47\tLoss:0.03485\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,48\tLoss:0.0374\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,49\tLoss:0.03686\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,50\tLoss:0.03894\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,51\tLoss:0.02769\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,52\tLoss:0.0387\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,53\tLoss:0.03128\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,54\tLoss:0.03027\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,55\tLoss:0.03985\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,56\tLoss:0.04676\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,57\tLoss:0.04747\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,58\tLoss:0.02719\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,59\tLoss:0.02531\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,60\tLoss:0.03496\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,61\tLoss:0.0394\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,62\tLoss:0.0232\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,63\tLoss:0.04064\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,64\tLoss:0.03277\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,65\tLoss:0.03293\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,66\tLoss:0.03173\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,67\tLoss:0.02499\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,68\tLoss:0.04337\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,69\tLoss:0.03186\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,70\tLoss:0.04003\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,71\tLoss:0.0229\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,72\tLoss:0.04123\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,73\tLoss:0.03783\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,74\tLoss:0.02482\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,75\tLoss:0.03234\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,76\tLoss:0.03012\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,77\tLoss:0.02328\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,78\tLoss:0.03027\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,79\tLoss:0.02699\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,80\tLoss:0.02907\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,81\tLoss:0.02702\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,82\tLoss:0.03739\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,83\tLoss:0.03529\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,84\tLoss:0.0274\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,85\tLoss:0.02582\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,86\tLoss:0.02923\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,87\tLoss:0.03334\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,88\tLoss:0.03192\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,89\tLoss:0.0425\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,90\tLoss:0.02698\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,91\tLoss:0.03077\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,92\tLoss:0.02886\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,93\tLoss:0.02019\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,94\tLoss:0.03217\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,95\tLoss:0.02802\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,96\tLoss:0.02908\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,97\tLoss:0.03372\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,98\tLoss:0.02342\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,99\tLoss:0.03011\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,100\tLoss:0.03085\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,101\tLoss:0.0224\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,102\tLoss:0.02292\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,103\tLoss:0.0258\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,104\tLoss:0.02014\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,105\tLoss:0.0255\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,106\tLoss:0.0289\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,107\tLoss:0.02749\tAllocated:naGB\tCached:naGB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "writer = SummaryWriter()\n",
    "iter_no = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        iter_no += 1\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).float()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(images)\n",
    "        #print((prediction[0], controls[0]))\n",
    "        loss = criterion(prediction, controls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_no % REPORT_EVERY_ITER == 0:\n",
    "            writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "            torch.save(net.state_dict(), \"snapshots/saved_model_{}\".format(loss.item()))\n",
    "        \n",
    "        out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "        print(out.format(str(epoch),\n",
    "                        str(iter_no),\n",
    "                        round(loss.item(),5),\n",
    "                         'na', 'na'\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                        ))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1050\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    2048\n"
     ]
    }
   ],
   "source": [
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
