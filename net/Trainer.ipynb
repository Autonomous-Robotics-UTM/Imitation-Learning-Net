{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n",
      "importing Jupyter notebook from Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "REPORT_EVERY_ITER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units after conv 768\n",
      "number of parameters:  1111969\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "dataloader = DataLoader(dataset, batch_size = 16, shuffle = True, num_workers = 16)\n",
    "\n",
    "net = ConvNet()\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(25248.6992)\n",
      "1 tensor(25210.4023)\n",
      "2 tensor(25175.0449)\n",
      "3 tensor(25128.2598)\n",
      "4 tensor(25061.4395)\n",
      "5 tensor(24963.9219)\n",
      "6 tensor(24830.5098)\n",
      "7 tensor(24642.6953)\n",
      "8 tensor(24384.8945)\n",
      "9 tensor(24029.7754)\n",
      "10 tensor(23544.4395)\n",
      "11 tensor(22908.0879)\n",
      "12 tensor(22064.6582)\n",
      "13 tensor(20961.4863)\n",
      "14 tensor(19563.3711)\n",
      "15 tensor(17809.9023)\n",
      "16 tensor(15671.4150)\n",
      "17 tensor(13230.2217)\n",
      "18 tensor(10650.3730)\n",
      "19 tensor(8380.2734)\n",
      "20 tensor(7167.8750)\n",
      "21 tensor(7605.4595)\n",
      "22 tensor(9400.8721)\n",
      "23 tensor(8598.7705)\n",
      "24 tensor(6738.5557)\n",
      "25 tensor(5804.5796)\n",
      "26 tensor(5707.9932)\n",
      "27 tensor(5100.5977)\n",
      "28 tensor(5568.7266)\n",
      "29 tensor(5420.1055)\n",
      "30 tensor(4775.6333)\n",
      "31 tensor(4671.5933)\n",
      "32 tensor(4178.5757)\n",
      "33 tensor(3535.5825)\n",
      "34 tensor(3571.3821)\n",
      "35 tensor(3185.0767)\n",
      "36 tensor(3175.0681)\n",
      "37 tensor(3104.3049)\n",
      "38 tensor(2815.5095)\n",
      "39 tensor(2743.8958)\n",
      "40 tensor(2358.3992)\n",
      "41 tensor(2443.5322)\n",
      "42 tensor(2266.7036)\n",
      "43 tensor(2238.3901)\n",
      "44 tensor(2102.9910)\n",
      "45 tensor(1849.9423)\n",
      "46 tensor(1828.3541)\n",
      "47 tensor(1673.0667)\n",
      "48 tensor(1714.1644)\n",
      "49 tensor(1537.7876)\n",
      "50 tensor(1513.5089)\n",
      "51 tensor(1368.4504)\n",
      "52 tensor(1362.8889)\n",
      "53 tensor(1239.9980)\n",
      "54 tensor(1203.9781)\n",
      "55 tensor(1100.3096)\n",
      "56 tensor(1084.7242)\n",
      "57 tensor(980.5101)\n",
      "58 tensor(948.7405)\n",
      "59 tensor(895.3953)\n",
      "60 tensor(866.6611)\n",
      "61 tensor(825.0714)\n",
      "62 tensor(763.6684)\n",
      "63 tensor(762.4839)\n",
      "64 tensor(725.6412)\n",
      "65 tensor(670.0481)\n",
      "66 tensor(663.8013)\n",
      "67 tensor(619.2325)\n",
      "68 tensor(583.7985)\n",
      "69 tensor(566.6002)\n",
      "70 tensor(511.0634)\n",
      "71 tensor(464.0599)\n",
      "72 tensor(441.4440)\n",
      "73 tensor(420.2954)\n",
      "74 tensor(383.8742)\n",
      "75 tensor(345.8335)\n",
      "76 tensor(311.8834)\n",
      "77 tensor(287.2714)\n",
      "78 tensor(268.7399)\n",
      "79 tensor(264.9263)\n",
      "80 tensor(281.2253)\n",
      "81 tensor(303.7976)\n",
      "82 tensor(320.1371)\n",
      "83 tensor(243.7529)\n",
      "84 tensor(153.5979)\n",
      "85 tensor(128.2636)\n",
      "86 tensor(167.6018)\n",
      "87 tensor(206.1095)\n",
      "88 tensor(169.5136)\n",
      "89 tensor(113.4538)\n",
      "90 tensor(62.0315)\n",
      "91 tensor(53.3848)\n",
      "92 tensor(82.5256)\n",
      "93 tensor(135.3506)\n",
      "94 tensor(246.7482)\n",
      "95 tensor(305.4428)\n",
      "96 tensor(292.9643)\n",
      "97 tensor(86.7571)\n",
      "98 tensor(42.1542)\n",
      "99 tensor(171.5297)\n",
      "0 tensor(59125.)\n",
      "1 tensor(47331.2383)\n",
      "2 tensor(35236.0234)\n",
      "3 tensor(30048.0020)\n",
      "4 tensor(28938.1191)\n",
      "5 tensor(28810.3613)\n",
      "6 tensor(28868.0488)\n",
      "7 tensor(28699.9688)\n",
      "8 tensor(28076.7227)\n",
      "9 tensor(27077.2539)\n",
      "10 tensor(25773.1641)\n",
      "11 tensor(24466.9746)\n",
      "12 tensor(23018.5977)\n",
      "13 tensor(21416.1777)\n",
      "14 tensor(19776.5078)\n",
      "15 tensor(18096.0039)\n",
      "16 tensor(16691.8906)\n",
      "17 tensor(15623.1973)\n",
      "18 tensor(14647.8652)\n",
      "19 tensor(13607.1318)\n",
      "20 tensor(12472.4990)\n",
      "21 tensor(11119.5166)\n",
      "22 tensor(9648.0527)\n",
      "23 tensor(8289.3838)\n",
      "24 tensor(7214.5864)\n",
      "25 tensor(6350.5278)\n",
      "26 tensor(5497.5083)\n",
      "27 tensor(4991.9917)\n",
      "28 tensor(5290.1172)\n",
      "29 tensor(4371.6328)\n",
      "30 tensor(2279.3340)\n",
      "31 tensor(2116.1462)\n",
      "32 tensor(3044.3406)\n",
      "33 tensor(1821.1888)\n",
      "34 tensor(930.5977)\n",
      "35 tensor(1744.5692)\n",
      "36 tensor(776.1151)\n",
      "37 tensor(686.3873)\n",
      "38 tensor(959.5051)\n",
      "39 tensor(191.3113)\n",
      "40 tensor(735.1210)\n",
      "41 tensor(268.3296)\n",
      "42 tensor(330.8604)\n",
      "43 tensor(387.5526)\n",
      "44 tensor(133.1515)\n",
      "45 tensor(389.4857)\n",
      "46 tensor(88.4674)\n",
      "47 tensor(331.6164)\n",
      "48 tensor(67.5785)\n",
      "49 tensor(260.7335)\n",
      "50 tensor(53.6529)\n",
      "51 tensor(198.0882)\n",
      "52 tensor(46.9952)\n",
      "53 tensor(145.5170)\n",
      "54 tensor(40.8927)\n",
      "55 tensor(115.0466)\n",
      "56 tensor(38.1804)\n",
      "57 tensor(92.9079)\n",
      "58 tensor(31.6245)\n",
      "59 tensor(75.0273)\n",
      "60 tensor(25.9261)\n",
      "61 tensor(59.4139)\n",
      "62 tensor(18.6832)\n",
      "63 tensor(45.9512)\n",
      "64 tensor(12.8990)\n",
      "65 tensor(37.4543)\n",
      "66 tensor(8.8875)\n",
      "67 tensor(30.7684)\n",
      "68 tensor(5.6045)\n",
      "69 tensor(25.6683)\n",
      "70 tensor(4.4445)\n",
      "71 tensor(21.6631)\n",
      "72 tensor(3.1709)\n",
      "73 tensor(17.3983)\n",
      "74 tensor(1.8407)\n",
      "75 tensor(14.0008)\n",
      "76 tensor(1.2402)\n",
      "77 tensor(11.2048)\n",
      "78 tensor(0.7235)\n",
      "79 tensor(9.0398)\n",
      "80 tensor(0.7370)\n",
      "81 tensor(7.6236)\n",
      "82 tensor(0.9869)\n",
      "83 tensor(6.5089)\n",
      "84 tensor(1.1063)\n",
      "85 tensor(5.4151)\n",
      "86 tensor(0.9874)\n",
      "87 tensor(4.3329)\n",
      "88 tensor(0.7257)\n",
      "89 tensor(3.3931)\n",
      "90 tensor(0.4515)\n",
      "91 tensor(2.5771)\n",
      "92 tensor(0.2171)\n",
      "93 tensor(2.0420)\n",
      "94 tensor(0.2050)\n",
      "95 tensor(1.7176)\n",
      "96 tensor(0.1580)\n",
      "97 tensor(1.4110)\n",
      "98 tensor(0.1516)\n",
      "99 tensor(1.2195)\n",
      "0 tensor(65697.9453)\n",
      "1 tensor(55662.9570)\n",
      "2 tensor(52233.2891)\n",
      "3 tensor(45983.9766)\n",
      "4 tensor(43625.1797)\n",
      "5 tensor(43286.1250)\n",
      "6 tensor(42937.0195)\n",
      "7 tensor(41883.2148)\n",
      "8 tensor(40274.1172)\n",
      "9 tensor(38431.3828)\n",
      "10 tensor(36417.9766)\n",
      "11 tensor(33886.0781)\n",
      "12 tensor(30933.8125)\n",
      "13 tensor(28408.0840)\n",
      "14 tensor(25991.7754)\n",
      "15 tensor(24215.6191)\n",
      "16 tensor(23758.5000)\n",
      "17 tensor(23501.9082)\n",
      "18 tensor(21904.0762)\n",
      "19 tensor(20448.4473)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-23f235810c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "writer = SummaryWriter()\n",
    "inter_no = 0\n",
    "\n",
    "# for i_batch, sampled_batch in enumerate(dataloader):\n",
    "#     for epoch in range(epochs):\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        inter_no += 1\n",
    "        images = sampled_batch['image'].float()\n",
    "        controls = sampled_batch['control'].float()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(images)\n",
    "        \n",
    "        loss = criterion(prediction, controls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if inter_no % REPORT_EVERY_ITER == 0:\n",
    "            writer.add_scalar(\"Loss\", loss.item(), inter_no)\n",
    "        \n",
    "        print(epoch, loss.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
