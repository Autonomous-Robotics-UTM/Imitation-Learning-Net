{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n",
      "importing Jupyter notebook from Model.ipynb\n",
      "units after conv 512\n",
      "conv parameters:  168224\n",
      "fc parameters:  164353\n",
      "input torch.Size([4, 3, 480, 640])\n",
      "output torch.Size([4, 1])\n",
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "REPORT_EVERY_ITER = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units after conv 512\n",
      "conv parameters:  168224\n",
      "fc parameters:  164353\n",
      "number of parameters:  332577\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)\n",
    "\n",
    "net = ConvNet().to(device)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99,4400\tLoss:0.00111\tAllocated:0.039GB\tCached:0.039GB\r"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "writer = SummaryWriter()\n",
    "iter_no = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        iter_no += 1\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).float()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(images)\n",
    "        \n",
    "        loss = criterion(prediction, controls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_no % REPORT_EVERY_ITER == 0:\n",
    "            writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "        \n",
    "        out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\"\n",
    "        print(out.format(str(epoch),\n",
    "                        str(iter_no),\n",
    "                        round(loss.item(),5),\n",
    "                        round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "                        round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                        ),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    3665920\n"
     ]
    }
   ],
   "source": [
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
