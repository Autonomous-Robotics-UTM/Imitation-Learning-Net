{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('using device', device(type='cpu'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "REPORT_EVERY_ITER = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Stack size', 1)\n",
      "('units after conv', 512)\n",
      "('conv parameters: ', 168224)\n",
      "('fc parameters: ', 164353)\n",
      "('Data size', 11018)\n",
      "('number of parameters: ', 332577)\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "print(\"Stack size\", dataset.stack_size)\n",
    "# dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)\n",
    "net = ConvNet().to(device)\n",
    "\n",
    "print(\"Data size\", dataset.data_frame.size)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "validation_split = .2\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "# spliting the dataset\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "# Training data loader #TODO \n",
    "dataloader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=train_sampler)\n",
    "\n",
    "# Validation data loader\n",
    "validLoader = DataLoader(dataset, batch_size = 256, num_workers = 0, sampler=valid_sampler)\n",
    "\n",
    "print(len(dataloader))\n",
    "print(len(validLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\tLoss:0.05935\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,2\tLoss:0.04808\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,3\tLoss:0.0698\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,4\tLoss:0.0435\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,5\tLoss:0.06472\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,6\tLoss:0.05344\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,7\tLoss:0.05261\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,8\tLoss:0.04632\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,9\tLoss:0.04518\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,10\tLoss:0.05029\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,11\tLoss:0.04766\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,12\tLoss:0.05506\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,13\tLoss:0.04393\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,14\tLoss:0.05144\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,15\tLoss:0.05188\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,16\tLoss:0.05526\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,17\tLoss:0.03742\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,18\tLoss:0.04996\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,19\tLoss:0.04647\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,20\tLoss:0.04963\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,21\tLoss:0.04038\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,22\tLoss:0.04393\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,23\tLoss:0.04527\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,24\tLoss:0.04766\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,25\tLoss:0.04617\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,26\tLoss:0.03958\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,27\tLoss:0.03505\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,28\tLoss:0.04377\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,29\tLoss:0.03793\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,30\tLoss:0.04066\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,31\tLoss:0.0486\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,32\tLoss:0.05115\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,33\tLoss:0.03813\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,34\tLoss:0.04832\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "0,35\tLoss:0.0392\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,36\tLoss:0.04044\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,37\tLoss:0.0392\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,38\tLoss:0.03769\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,39\tLoss:0.05052\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,40\tLoss:0.04253\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,41\tLoss:0.03765\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,42\tLoss:0.0377\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,43\tLoss:0.04034\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,44\tLoss:0.03786\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,45\tLoss:0.03185\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,46\tLoss:0.03194\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,47\tLoss:0.03485\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,48\tLoss:0.0374\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,49\tLoss:0.03686\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,50\tLoss:0.03894\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,51\tLoss:0.02769\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,52\tLoss:0.0387\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,53\tLoss:0.03128\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,54\tLoss:0.03027\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,55\tLoss:0.03985\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,56\tLoss:0.04676\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,57\tLoss:0.04747\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,58\tLoss:0.02719\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,59\tLoss:0.02531\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,60\tLoss:0.03496\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,61\tLoss:0.0394\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,62\tLoss:0.0232\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,63\tLoss:0.04064\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,64\tLoss:0.03277\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,65\tLoss:0.03293\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,66\tLoss:0.03173\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,67\tLoss:0.02499\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,68\tLoss:0.04337\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,69\tLoss:0.03186\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "1,70\tLoss:0.04003\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,71\tLoss:0.0229\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,72\tLoss:0.04123\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,73\tLoss:0.03783\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,74\tLoss:0.02482\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,75\tLoss:0.03234\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,76\tLoss:0.03012\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,77\tLoss:0.02328\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,78\tLoss:0.03027\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,79\tLoss:0.02699\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,80\tLoss:0.02907\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,81\tLoss:0.02702\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,82\tLoss:0.03739\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,83\tLoss:0.03529\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,84\tLoss:0.0274\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,85\tLoss:0.02582\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,86\tLoss:0.02923\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,87\tLoss:0.03334\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,88\tLoss:0.03192\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,89\tLoss:0.0425\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,90\tLoss:0.02698\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,91\tLoss:0.03077\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,92\tLoss:0.02886\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,93\tLoss:0.02019\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,94\tLoss:0.03217\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,95\tLoss:0.02802\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,96\tLoss:0.02908\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,97\tLoss:0.03372\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,98\tLoss:0.02342\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,99\tLoss:0.03011\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,100\tLoss:0.03085\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,101\tLoss:0.0224\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,102\tLoss:0.02292\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,103\tLoss:0.0258\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,104\tLoss:0.02014\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "2,105\tLoss:0.0255\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,106\tLoss:0.0289\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,107\tLoss:0.02749\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,108\tLoss:0.02096\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,109\tLoss:0.02113\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,110\tLoss:0.02949\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,111\tLoss:0.02805\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,112\tLoss:0.02631\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,113\tLoss:0.02691\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,114\tLoss:0.03193\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,115\tLoss:0.02682\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,116\tLoss:0.02581\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,117\tLoss:0.02251\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,118\tLoss:0.02049\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,119\tLoss:0.02433\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,120\tLoss:0.01612\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,121\tLoss:0.0291\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,122\tLoss:0.02329\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,123\tLoss:0.02003\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,124\tLoss:0.02243\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,125\tLoss:0.01859\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,126\tLoss:0.02006\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,127\tLoss:0.02391\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,128\tLoss:0.02209\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,129\tLoss:0.02058\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,130\tLoss:0.03103\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,131\tLoss:0.02152\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,132\tLoss:0.022\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,133\tLoss:0.01722\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,134\tLoss:0.02687\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,135\tLoss:0.0181\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,136\tLoss:0.02338\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,137\tLoss:0.0232\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,138\tLoss:0.02254\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,139\tLoss:0.02425\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "3,140\tLoss:0.02962\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,141\tLoss:0.01671\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,142\tLoss:0.01935\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,143\tLoss:0.01672\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,144\tLoss:0.01523\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,145\tLoss:0.02012\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,146\tLoss:0.0228\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,147\tLoss:0.01946\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,148\tLoss:0.02024\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,149\tLoss:0.01813\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,150\tLoss:0.01679\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,151\tLoss:0.02081\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,152\tLoss:0.01737\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,153\tLoss:0.0227\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,154\tLoss:0.01797\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,155\tLoss:0.01958\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,156\tLoss:0.01404\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,157\tLoss:0.02105\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,158\tLoss:0.01829\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,159\tLoss:0.02106\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,160\tLoss:0.02112\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,161\tLoss:0.01802\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,162\tLoss:0.01671\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,163\tLoss:0.0254\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,164\tLoss:0.01795\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,165\tLoss:0.0194\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,166\tLoss:0.01779\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,167\tLoss:0.01746\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,168\tLoss:0.02006\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,169\tLoss:0.0198\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,170\tLoss:0.01877\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,171\tLoss:0.01544\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,172\tLoss:0.01712\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,173\tLoss:0.02271\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,174\tLoss:0.02517\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "4,175\tLoss:0.01709\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,176\tLoss:0.01669\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,177\tLoss:0.01902\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,178\tLoss:0.01855\tAllocated:naGB\tCached:naGB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,179\tLoss:0.01737\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,180\tLoss:0.02243\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,181\tLoss:0.01816\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,182\tLoss:0.02054\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,183\tLoss:0.01598\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,184\tLoss:0.01328\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,185\tLoss:0.01577\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,186\tLoss:0.01308\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,187\tLoss:0.01546\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,188\tLoss:0.01548\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,189\tLoss:0.01795\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,190\tLoss:0.01653\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,191\tLoss:0.01455\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,192\tLoss:0.01495\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,193\tLoss:0.01583\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,194\tLoss:0.01451\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,195\tLoss:0.01995\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,196\tLoss:0.01392\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,197\tLoss:0.01125\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,198\tLoss:0.016\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,199\tLoss:0.01467\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,200\tLoss:0.01224\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,201\tLoss:0.01301\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,202\tLoss:0.01299\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,203\tLoss:0.01772\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,204\tLoss:0.01571\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,205\tLoss:0.01435\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,206\tLoss:0.01419\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,207\tLoss:0.01238\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,208\tLoss:0.01324\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,209\tLoss:0.01531\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "5,210\tLoss:0.01228\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,211\tLoss:0.01349\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,212\tLoss:0.01239\tAllocated:naGB\tCached:naGB\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8a05ea49d37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print((prediction[0], controls[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "writer = SummaryWriter()\n",
    "iter_no = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        iter_no += 1\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).float()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(images)\n",
    "        #print((prediction[0], controls[0]))\n",
    "        loss = criterion(prediction, controls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_no % REPORT_EVERY_ITER == 0:\n",
    "            writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "            torch.save(net.state_dict(), \"snapshots/saved_model_{}\".format(loss.item()))\n",
    "        \n",
    "        out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "        print(out.format(str(epoch),\n",
    "                        str(iter_no),\n",
    "                        round(loss.item(),5),\n",
    "                         'na', 'na'\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                        ))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,1\tLoss:0.11308\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,2\tLoss:0.1104\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,3\tLoss:0.10524\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,4\tLoss:0.12263\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,5\tLoss:0.15256\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,6\tLoss:0.08564\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,7\tLoss:0.11901\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,8\tLoss:0.13282\tAllocated:naGB\tCached:naGB\n",
      "\n",
      "6,9\tLoss:0.15726\tAllocated:naGB\tCached:naGB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Test\n",
    "iter_no = 0\n",
    "for i_batch, sampled_batch in enumerate(validLoader):\n",
    "    iter_no += 1\n",
    "    images = sampled_batch['image'].to(device).float()\n",
    "    controls = sampled_batch['control'].to(device).float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    prediction = net(images)\n",
    "    loss = criterion(prediction, controls)\n",
    "    out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "    print(out.format(str(epoch),\n",
    "                    str(iter_no),\n",
    "                    round(loss.item(),5),\n",
    "                     'na', 'na'\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "#                         round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                    ))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1050\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    2048\n"
     ]
    }
   ],
   "source": [
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
