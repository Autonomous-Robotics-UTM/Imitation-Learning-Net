{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n",
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training stacks 441\n",
      "Total validation stacks 111\n"
     ]
    }
   ],
   "source": [
    "dataset = ControlsDataset()\n",
    "dataset.labels.num_categories = 21\n",
    "dataset.labels.transform.categorize(1.05, -1.05, 21)\n",
    "dataset.labels.infotype = \"Category\"\n",
    "dataset.make_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11018"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# resnet50.fc = nn.Sequential(nn.Linear(2048, 21))\n",
    "resnet50.fc = nn.Sequential(nn.Linear(2048, 1))\n",
    "\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont need\n",
    "counts = dataset.labels.dataframe.groupby('Category')['ID'].count()\n",
    "counts = np.array(counts)\n",
    "ratio = max(counts)/counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(4, 3)\n",
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# dont need\n",
    "A = np.ones((4,3))\n",
    "B = np.arange(3)\n",
    "print(B.shape)\n",
    "print(A.shape)\n",
    "\n",
    "R = np.multiply(B,A).T\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 21)\n",
      "(20, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.3188e+01, 1.3310e+02, 8.7566e+01, 7.7384e+01, 4.5582e+01, 3.0388e+01,\n",
      "        1.5921e+01, 1.7606e+01, 7.6144e+00, 5.8275e+00, 1.0000e+00, 2.8199e+01,\n",
      "        4.3214e+01, 1.0734e+02, 7.0053e+01, 6.7908e+01, 9.1164e+01, 2.4648e+02,\n",
      "        1.4160e+02, 1.6638e+03, 6.7222e+01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# dont need\n",
    "batch_size = 20\n",
    "index = 10\n",
    "controls = np.arange(batch_size).reshape((batch_size,1))\n",
    "mu = controls\n",
    "variance = 2\n",
    "sigma = np.sqrt(variance)\n",
    "x = np.zeros((batch_size,21))\n",
    "x[:] = np.linspace(0, 21, 21)\n",
    "print(x.shape)\n",
    "print(mu.shape)\n",
    "pdf = stats.norm.pdf(x, mu, sigma)\n",
    "maximum = 0.27\n",
    "pdf = (maximum-pdf)/maximum\n",
    "\n",
    "plt.xlim([0,21])\n",
    "plt.ylim([0,1.2])\n",
    "plt.plot(x[0], pdf[0])\n",
    "plt.title(\"Weights Representation\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.show()\n",
    "\n",
    "weights = ratio\n",
    "weights = torch.Tensor(weights).to(device)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "optimizer = optim.Adam(resnet50.parameters())\n",
    "#criterion = nn.CrossEntropyLoss(weight=weights,reduction='none') # Changed from Mean-Squared to Cross-Entro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score for classification\n",
    "def score(model,device,dataset,single_batch = False):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i_batch, sampled_batch in enumerate(dataset.validloader):\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).long()\n",
    "        controls = torch.flatten(controls)\n",
    "        prediction = model(images)\n",
    "\n",
    "        maximum = torch.argmax(prediction,dim = 1)\n",
    "        shared = maximum == controls\n",
    "        shared = 1 * shared\n",
    "        correct += int(torch.sum(shared))\n",
    "        total += len(controls)\n",
    "        if single_batch:\n",
    "            return (total,correct)\n",
    "    return (total,correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f4d72d99a84abb8b7cfb5b1d7c332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0', max=441.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n",
      "saved to tensorboard\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[20, 1]' is invalid for input of size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b85becce47f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[20, 1]' is invalid for input of size 15"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "resnet50.train()\n",
    "iter_no = 0\n",
    "report_period = 20\n",
    "percent = 0\n",
    "for epoch in range(epochs):\n",
    "    for i_batch, sampled_batch in tqdm_notebook(enumerate(dataset.dataloader),\n",
    "                                                total=len(dataset.dataloader),\n",
    "                                                desc= str(percent)):\n",
    "        #inputs and forward pass\n",
    "        images = sampled_batch['image'].to(device).float()\n",
    "        controls = sampled_batch['control'].to(device).long()\n",
    "        controls = torch.flatten(controls)\n",
    "\n",
    "        #backwards pass\n",
    "        optimizer.zero_grad()\n",
    "        prediction = resnet50(images)\n",
    "        #print(torch.argmax(prediction,dim=1))\n",
    "        #print\n",
    "        #print(controls)\n",
    "        \n",
    "        batch_size = 20\n",
    "        index = 10\n",
    "        mu = controls.reshape((batch_size,1))\n",
    "        variance = 2\n",
    "        sigma = np.sqrt(variance)\n",
    "        x = np.zeros((batch_size,21))\n",
    "        x[:] = np.linspace(0, 21, 21)\n",
    "        #print(x.shape)\n",
    "        #print(mu.shape)\n",
    "        pdf = stats.norm.pdf(x, mu.cpu(), sigma)\n",
    "        maximum = 0.27\n",
    "        inv = (maximum-pdf)/maximum\n",
    "        inv = torch.Tensor(inv).to(device)\n",
    "        \n",
    "        prediction = torch.abs(prediction)\n",
    "        \n",
    "        #loss = criterion(prediction, controls)\n",
    "        loss = torch.mean(prediction*inv)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter_no += 1\n",
    "        if iter_no % report_period == 0:\n",
    "            #self.writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "            print(\"saved to tensorboard\")\n",
    "            #self.save(epoch,\"snapshots/{:.3f}_model.pt\".format(loss.item()))\n",
    "\n",
    "    out = \"{0},{1}\\tLoss:{2}\\tAllocated:{3}GB\\tCached:{4}GB\\n\"\n",
    "    print(out.format(str(epoch),\n",
    "                    str(iter_no),\n",
    "                    round(loss.item(),5),\n",
    "                     'na', 'na'\n",
    "                     #round(torch.cuda.memory_allocated(0)/1024**3,3),\n",
    "                     #round(torch.cuda.memory_allocated(0)/1024**3,3)\n",
    "                    ))\n",
    "    epoch_score = score(resnet50,device,dataset,True)\n",
    "    total,correct = epoch_score\n",
    "    percent = round(epoch_score[1]/epoch_score[0],3)*100\n",
    "    #print(correct)\n",
    "    #print(prediction)\n",
    "    print(\"Accuracy: {}%\".format(correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(epoch,model,path):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict()},\n",
    "            path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(100,resnet50,\"resnet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
