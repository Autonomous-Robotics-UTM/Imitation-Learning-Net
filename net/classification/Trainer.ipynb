{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8aacf0ffccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCustomDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlsDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CSC493/self-driving-rl/net/classification/CustomDataset.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_init_module_attrs\u001b[0;34m(spec, module, override)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "from Model import ConvNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ControlsDataset()\n",
    "dataset.labels.num_categories = 21\n",
    "dataset.labels.transform.categorize(1.05, -1.05, 21)\n",
    "dataset.images.set_grayscale(False)\n",
    "print(\"Data size\", len(dataset.labels))\n",
    "dataset.make_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet(color_channels = 3, outputs = 14, dataset = dataset).to(device)\n",
    "#net = ConvNet(color_channels = 1, outputs = 21, dataset = dataset).to(device)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.labels.dataframe)\n",
    "counts = dataset.labels.dataframe.groupby('Category')['ID'].count()\n",
    "array = np.array(counts)\n",
    "print(array)\n",
    "print(len(array))\n",
    "dataset.labels.histogram()\n",
    "# weights = max(counts)/array\n",
    "# weights = torch.Tensor(weights).to(device)\n",
    "# print(weights)\n",
    "ratio = max(counts)/array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, variance = 10.5, 4\n",
    "sigma = math.sqrt(variance) \n",
    "x = np.linspace(0, 21, 21)\n",
    "pdf = stats.norm.pdf(x, mu, sigma)\n",
    "inv = ((np.ones(len(x)) * (max(pdf))) - pdf)/max(pdf) + 1\n",
    "\n",
    "plt.xlim([0,21])\n",
    "plt.ylim([0,1.2])\n",
    "plt.plot(x, inv)\n",
    "plt.title(\"Weights Representation\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.show()\n",
    "\n",
    "weights = ratio\n",
    "weights = torch.Tensor(weights).to(device)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "uniform.cdf([0, 1, 2, 3, 4, 5], loc=1, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "net.conv1.register_forward_hook(get_activation('conv1'))\n",
    "data, _ = dataset[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model(data)\n",
    "\n",
    "act = activation['conv1'].squeeze()\n",
    "fig, axarr = plt.subplots(act.size(0))\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[idx].imshow(act[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "print(type(weights))\n",
    "criterion = nn.CrossEntropyLoss(weight=weights) # Changed from Mean-Squared to Cross-Entropy\n",
    "#criterion = nn.MSELoss()\n",
    "net.report_period = 20\n",
    "\n",
    "net.optimizer = optimizer\n",
    "#net.load(\"snapshots/1.217_model.pt\")\n",
    "\n",
    "net.fit(device,epochs,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of training Validation Test\n",
    "#net.load(\"snapshots/0.727_model.pt\")\n",
    "#total, correct = net.score(device,dataset, \"categorical\")\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "for i_batch, sampled_batch in enumerate(dataset.validloader):\n",
    "    images = sampled_batch['image'].to(device).float()\n",
    "    controls = sampled_batch['control'].to(device).long()\n",
    "    controls = torch.flatten(controls)\n",
    "    prediction = net(images)\n",
    "\n",
    "    maximum = torch.argmax(prediction,dim = 1)\n",
    "    print(maximum)\n",
    "    print(controls)\n",
    "    shared = maximum == controls\n",
    "    shared = 1 * shared\n",
    "    correct += int(torch.sum(shared))\n",
    "    total += len(controls)\n",
    "\n",
    "print(\"{:.1f}% classified correctly\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning of training Validation Test\n",
    "net.load(\"snapshots/3.002_model.pt\")\n",
    "total, correct = net.score(device,dataset, \"categorical\")\n",
    "print(\"{:.1f}% classified correctly\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute adversarial noise given a trained net \n",
    "def compute_noise(net, lr, data_sample):\n",
    "    input_img = data_sample['image'].to(device).float()\n",
    "    control = data_sample['control'].to(device).long()\n",
    "    \n",
    "    # remember grad for image for adversarial attack\n",
    "    input_img.requires_grad = True\n",
    "\n",
    "    # pass img through the net \n",
    "    output = net(input_img)\n",
    "    pred = torch.argmax(output, dim = 1)\n",
    "    if pred != control:\n",
    "        # nothing to fool if prediction aint right in the first place  \n",
    "        return 0\n",
    "\n",
    "    loss = F.nll_loss(output, control)\n",
    "    # zero out gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # get all the gradient data for computing adversarial noise \n",
    "    grads = input_img.grad.data\n",
    "\n",
    "    # get element-wise sign of grad data\n",
    "    # idk the tutorial did this: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "    grads_signs = grads.sign()\n",
    "\n",
    "    # create adversarial noise\n",
    "    adv_noise = lr*grads_signs\n",
    "\n",
    "    # compute adverarial image by adding noise to input image\n",
    "    adv_input = input_img + adv_noise\n",
    "\n",
    "    # run net on adv_image and see if we succeded in fooling it \n",
    "    adv_output = net(adv_input)\n",
    "    adv_pred = torch.argmax(adv_output, dim = 1)\n",
    "    if adv_pred == control:\n",
    "        # adv attack failed, either net is good or my code is bad \n",
    "        return -1\n",
    "    else:\n",
    "        return adv_noise, adv_input, pred, adv_pred, control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Info when using cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
