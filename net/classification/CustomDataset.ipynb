{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import math\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labels():\n",
    "    def __init__(self,path):\n",
    "        self.dataframe = pd.read_csv(path)\n",
    "        self.transform = LabelTransform(self)\n",
    "        self.override_params = True\n",
    "        #categorical attributes\n",
    "        self.maximum = 1.05\n",
    "        self.minimum = -1.05\n",
    "        #directional attributes\n",
    "        self.directions = {\"left\":[[-1.05,0]],\"straight\":[[-0.01,0.01]],\"right\":[[0,1.05]]}\n",
    "        self.infotype = \"Category\"\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataframe.iloc[index][self.infotype]\n",
    "    \n",
    "    def histogram(self):\n",
    "        return self.dataframe[self.infotype].hist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelTransform():\n",
    "    def __init__(self,labels):\n",
    "        self.labels = labels.dataframe\n",
    "        \n",
    "    def column_rule(self,column_name, function):\n",
    "        self.labels[column_name] = self.labels.apply(lambda x: function(x.Angle), axis=1)\n",
    "        \n",
    "    def categorize(self, maximum, minimum, num_categories):\n",
    "        def func(angle):\n",
    "            if angle == maximum:\n",
    "                return num_categories - 1\n",
    "            scale = num_categories/(maximum-minimum)\n",
    "            return math.floor(scale*(angle-minimum))\n",
    "        \n",
    "        #apply the categorization to the column\n",
    "        self.column_rule(\"Category\",func)\n",
    "        \n",
    "        #return the categories created\n",
    "        num_range = np.linspace(minimum,maximum,num_categories+1)\n",
    "        categories = [[round(num_range[i],3), round(num_range[i+1],3)] for i in range(len(num_range)-1)]\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    def directionalize(self,directions):\n",
    "        def direction(angle):\n",
    "            for key in directions:\n",
    "                for interval in directions[key]:\n",
    "                    start,end = interval\n",
    "                    if start < angle and end > angle:\n",
    "                        return key\n",
    "        self.labels['Direction'] = self.labels.apply(lambda x: direction(x.Angle), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images():\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self.transform = ImageTransform()\n",
    "        self.stack_size = 1\n",
    "        self.grayscale = False\n",
    "        \n",
    "    def image_filename(self,path, number):\n",
    "        return \"{0}{number:06}.jpg\".format(path,number=number)\n",
    "        \n",
    "    def get_stack(self,index,stack_size):\n",
    "        img_filenames = [self.image_filename(self.path,i) \n",
    "                         for i in range(index, index+stack_size)]\n",
    "        images = np.array([io.imread(img_filename).transpose((2,0,1)) for img_filename in img_filenames])\n",
    "        images = self.transform.apply(images)/255\n",
    "        if not self.grayscale:\n",
    "            images = np.concatenate(images, axis=0)\n",
    "        return images\n",
    "    \n",
    "    def show(self,stack):\n",
    "        stack = stack.squeeze()\n",
    "        if self.grayscale:\n",
    "            f, ax = plt.subplots(stack_size, 1, figsize=(1*self.stack_size,25))\n",
    "            ax.imshow(stack,cmap='gray')\n",
    "            \n",
    "        else:\n",
    "            f, ax = plt.subplots(stack_size, 3, figsize=(3*self.stack_size,25))\n",
    "            ax = ax.reshape((self.stack_size,3))\n",
    "            for k in range(3*self.stack_size):\n",
    "                i,j = k//3, k % 3\n",
    "                ax[i,j].imshow(stack[k],cmap='gray')\n",
    "                \n",
    "        \n",
    "            \n",
    "    def set_grayscale(self, switch):\n",
    "        if self.grayscale != switch:\n",
    "            self.grayscale = switch\n",
    "            if switch:\n",
    "                self.transform.add(\"grayscale\")\n",
    "            else:\n",
    "                self.transform.remove(\"grayscale\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self):\n",
    "        self.transformations = []\n",
    "        \n",
    "    def apply(self,images):\n",
    "        for transformation in self.transformations:\n",
    "            function = getattr(self,transformation)\n",
    "            images = function(images)\n",
    "        return images\n",
    "    \n",
    "    def add(self,name):\n",
    "        self.transformations.append(name)\n",
    "        \n",
    "    def remove(self,name):\n",
    "        if name in self.transformations:\n",
    "            self.transformations.remove(name)\n",
    "    \n",
    "    def grayscale(self,images):\n",
    "        if images.shape[1] != 3:\n",
    "            return images\n",
    "        r, g, b = images[:,0,:,:], images[:,1,:,:], images[:,2,:,:]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlsDataset(Dataset):\n",
    "    \"\"\"Dataset that maps camera images into steering angle\"\"\"\n",
    "    def __init__(self,stack_size = 1 ,img_folder = '../data/selected/', csv_path='../data/selected/data.csv'):\n",
    "        self.stack_size = stack_size\n",
    "        self.images = Images(img_folder)\n",
    "        self.labels = Labels(csv_path)\n",
    "    \n",
    "    def make_dataloaders(self,train=0.8,test=0.2):\n",
    "        \n",
    "        indices = list(range(len(self)))\n",
    "        split = int(np.floor(test * len(self)))\n",
    "\n",
    "        # spliting the dataset\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        # Creating PT data samplers and loaders:\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        # Training data loader # NOTE had to remove shuffle\n",
    "        self.dataloader = DataLoader(self, batch_size = 128, num_workers = 0, sampler=train_sampler)\n",
    "\n",
    "        # Validation data loader # NOTE had to remove shuffle\n",
    "        self.validloader = DataLoader(self, batch_size = 128, num_workers = 0, sampler=valid_sampler)\n",
    "\n",
    "        print(\"Total training stacks\", len(self.dataloader))\n",
    "        print(\"Total validation stacks\",len(self.validloader))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels) - self.stack_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #get a stack of images\n",
    "        image_stack = self.images.get_stack(idx,self.stack_size)\n",
    "        # use the latest image as the control\n",
    "        label = self.labels[idx+self.stack_size]\n",
    "        label = np.array([label])\n",
    "        #combine stack and label together\n",
    "        sample = {'image': image_stack, \n",
    "                  'control': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampledDataset(ControlsDataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.unique = {}\n",
    "        \n",
    "    def categorical_median_sample(self):\n",
    "        import statistics\n",
    "        for element in enumerate(self.labels):\n",
    "            num, category = element\n",
    "            if category not in self.unique:\n",
    "                self.unique[category] = [num]\n",
    "            else:\n",
    "                self.unique[category].append(num)\n",
    "                \n",
    "            #print(\"id: {0},cat: {1}\".format(element[0],element[1]))\n",
    "        \n",
    "        for key in self.unique:\n",
    "            print(\"cat: {}, count: {}\".format(key,len(self.unique[key])))\n",
    "            \n",
    "        lengths = [len(self.unique[key]) for key in self.unique]\n",
    "        print(statistics.median(lengths))\n",
    "        \n",
    "    def frame_rate(self, frame_rate):\n",
    "        print(self.labels.dataframe.shape)\n",
    "        newDataFrame = self.labels.dataframe.iloc[::frame_rate,:]\n",
    "        print(newDataFrame.shape)\n",
    "        \n",
    "        self.labels.dataframe = newDataFrame\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Labels' object has no attribute 'set_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bb5ef2951932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstack_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mControlsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#dataset.images.transform.add(\"grayscale\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#dataset.images.set_grayscale(True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Labels' object has no attribute 'set_type'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stack_size = 1\n",
    "    dataset = ControlsDataset(stack_size)\n",
    "    dataset.labels.set_type(\"categorical\")\n",
    "    #dataset.images.transform.add(\"grayscale\")\n",
    "    #dataset.images.set_grayscale(True)\n",
    "    dataloader = DataLoader(dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "    \n",
    "    img_stack = dataset[0]['image']\n",
    "    #dataset.images.show(img_stack)\n",
    "    \n",
    "    sampled_set = SampledDataset(dataset.images, dataset.labels)\n",
    "    sampled_set.frame_rate(6)\n",
    "#     sampled_set.categorical_median_sample()\n",
    "    #print(dataset.labels.dataframe)\n",
    "#     dataset.labels.frame_rate(4)\n",
    "    counts = dataset.labels.dataframe.groupby('Category')['ID'].count()\n",
    "    print(counts)\n",
    "    print(max(counts))\n",
    "    dataset.labels.histogram()\n",
    "    \n",
    "    #f, ax = plt.subplots(stack_size, 1, figsize=(1*stack_size,25))\n",
    "    #img_stack = img_stack.squeeze()\n",
    "    #ax.imshow(img_stack,cmap='gray')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
