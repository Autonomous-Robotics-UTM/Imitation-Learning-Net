{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Regression Model\n",
    "class RegConvNet(nn.Module):\n",
    "    def __init__(self, color_channels, outputs, dataset):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.channels = color_channels\n",
    "        self.report_period = 20\n",
    "        self.writer = SummaryWriter\n",
    "        self.start_epoch = 0\n",
    "        self.infotype = dataset.labels.infotype\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = dataset.dataloader\n",
    "\n",
    "        self.optimizer = None\n",
    "\n",
    "        img_size = torch.Size([1, color_channels, 170, 640])\n",
    "\n",
    "        self.convLayers = nn.Sequential(\n",
    "            nn.Conv2d(color_channels, 24, 5, stride=2),  # in_channels, out_channels, kernel_size,\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(24, 36, 5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(36, 48, 5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Dropout(0.25) # Dropping elements with a 25% chance\n",
    "        )\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(in_features=64*2*33, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=10),  # output features was 10\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input = input.view(input.size(0), 3, 70, 320)\n",
    "        input = self.convLayers(input)\n",
    "        print(input.shape)\n",
    "\n",
    "        input = input.view(input.size(0), -1)\n",
    "\n",
    "        output = self.FC(input)\n",
    "        return output\n",
    "\n",
    "    def accuracy(self, predictions, target):\n",
    "        totalCorrect = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] == target[i]:\n",
    "                totalCorrect += 1\n",
    "\n",
    "        return totalCorrect/len(target)\n",
    "\n",
    "    def fit(self, device, epochs, optimizer, criterion):\n",
    "        self.train()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        trainLoss  = 0\n",
    "        iter_no = 0\n",
    "\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "\n",
    "            for iBatch, sampledBatch in enumerate(self.dataloader):\n",
    "\n",
    "                images = sampledBatch['image'].to(device).float()\n",
    "                controls = sampledBatch['control'].to(device).float()\n",
    "                controls = torch.flatten(controls)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predictions = self(images)\n",
    "                predictions = torch.flatten(predictions)\n",
    "                # print(predictions)\n",
    "                # print(controls)\n",
    "\n",
    "                loss = criterion(predictions, controls)\n",
    "                print(\"Loss\", loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "                print(\"Accuracy\", self.accuracy(predictions, controls))\n",
    "                # trainLoss += loss.data[0].item()\n",
    "\n",
    "                # if iBatch % self.report_period == 0:\n",
    "                #     print(\"Loss:\", loss)\n",
    "\n",
    "                iter_no += 1\n",
    "                if iter_no % self.report_period == 0:\n",
    "                    self.writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "                    print(\"saved to tensorboard\")\n",
    "                    if self.channels < 3:\n",
    "                        self.save(epoch, \"snapshotsGray/{:.3f}_model.pt\".format(loss.item()))\n",
    "                    else:\n",
    "                        self.save(epoch, \"snapshots/{:.3f}_model.pt\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ClassConvNet(nn.Module):\n",
    "    def __init__(self, color_channels, outputs):\n",
    "        super(ClassConvNet, self).__init__()\n",
    "\n",
    "        self.channels = color_channels\n",
    "        self.report_period = 20\n",
    "        self.writer = SummaryWriter\n",
    "        self.start_epoch = 0\n",
    "#         self.infotype = dataset.labels.infotype\n",
    "#         self.dataset = dataset\n",
    "#         self.dataloader = dataset.dataloader\n",
    "\n",
    "        self.optimizer = None\n",
    "    \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(color_channels, 24, 5, stride=2),  # in_channels, out_channels, kernel_size,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(24, 36, 5, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(36, 48, 5, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(48, 64, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "#         self.convLayers = nn.Sequential(\n",
    "#             nn.Conv2d(color_channels, 24, 5, stride=2),  # in_channels, out_channels, kernel_size,\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(24, 36, 5, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(36, 48, 5, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(48, 64, 3),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 64, 3),\n",
    "# #             nn.Dropout(0.25)\n",
    "#         )\n",
    "        \n",
    "#         img_size = torch.Size([1, color_channels, 220, 400]) # [batch_size, channels, height, width]\n",
    "#         empty = torch.zeros(img_size)\n",
    "        \n",
    "#         units = self.convLayers(empty).numel()\n",
    "#         print('units', units)\n",
    "    \n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(in_features=64*20*43, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=25),  # output features was 10\n",
    "            nn.Linear(in_features=25, out_features=outputs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, image):\n",
    "#         print(image.size(0))\n",
    "#         image = image.view(image.size(0), self.channels, 110, 200)\n",
    "\n",
    "        out = self.conv1(image)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        \n",
    "        print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        print(out.shape)\n",
    "        out = self.FC(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         print(input.shape)\n",
    "# #         input = input.view(input.size(0), self.channels, 110, 200)\n",
    "#         print(\"IN forward\")\n",
    "#         input = self.convLayers(input)\n",
    "        \n",
    "#         print(\"inputShape\", input.shape)\n",
    "#         input = input.view(input.size(0), -1)\n",
    "#         output = self.FC(input)\n",
    "#         return output\n",
    "\n",
    "\n",
    "    def accuracy(self, predictions, target):\n",
    "        totalCorrect = 0\n",
    "        for i in range(len(predictions)):\n",
    "            values, indices = torch.max(predictions[i], 0)\n",
    "            if indices == target[i]:\n",
    "                totalCorrect += 1\n",
    "\n",
    "        return (totalCorrect/len(target)) * 100\n",
    "\n",
    "    def fit(self, device, epochs, optimizer, criterion):\n",
    "        self.train()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        trainLoss = 0\n",
    "        trainAccuracy = []\n",
    "        iter_no = 0\n",
    "\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "\n",
    "            for iBatch, sampledBatch in enumerate(self.dataloader):\n",
    "\n",
    "                images = sampledBatch['image'].to(device).float()\n",
    "                controls = sampledBatch['control'].to(device).long()\n",
    "                controls = torch.flatten(controls)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                # print(\"Controls\", controls)\n",
    "                # exit(1)\n",
    "\n",
    "                predictions = self(images)\n",
    "                # print(\"Predictions\", predictions)\n",
    "                loss = criterion(predictions, controls)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tAccuracy = self.accuracy(predictions, controls)\n",
    "                print(\"[%d, %d] Loss:\" %(epoch, iBatch), loss)\n",
    "                print(\"Accuracy\", tAccuracy)\n",
    "\n",
    "                trainAccuracy.append(tAccuracy)\n",
    "\n",
    "                iter_no += 1\n",
    "                if iter_no % self.report_period == 0:\n",
    "                    self.writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "                    print(\"saved to tensorboard\")\n",
    "                    if self.channels < 3:\n",
    "                        self.save(epoch, \"snapshotsGray/gray_{:.3f}_model.pt\".format(loss.item()))\n",
    "                    else:\n",
    "                        self.save(epoch, \"snapshots/{:.3f}_model.pt\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ClassConvNetNorm(nn.Module):\n",
    "    def __init__(self, color_channels, outputs, dataset):\n",
    "        super(ClassConvNetNorm, self).__init__()\n",
    "\n",
    "        self.channels = color_channels\n",
    "        self.report_period = 20\n",
    "        self.writer = SummaryWriter\n",
    "        self.start_epoch = 0\n",
    "        self.infotype = dataset.labels.infotype\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = dataset.dataloader\n",
    "\n",
    "        self.optimizer = None\n",
    "\n",
    "        self.convLayers = nn.Sequential(\n",
    "            nn.Conv2d(color_channels, 24, 5, stride=2, bias=False),  # in_channels, out_channels, kernel_size,\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(24),\n",
    "\n",
    "            nn.Conv2d(24, 36, 5, stride=2, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(36),\n",
    "\n",
    "            nn.Conv2d(36, 48, 5, stride=2, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(48),\n",
    "\n",
    "            nn.Conv2d(48, 64, 3, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 64, 3, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        img_size = torch.Size([1, color_channels, 220, 400]) # [batch_size, channels, height, width]\n",
    "        empty = torch.zeros(img_size)\n",
    "        \n",
    "        units = self.convLayers(empty).numel()\n",
    "        print('units', units)\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(in_features=64*2*33, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=25),  # output features was 10\n",
    "            nn.Linear(in_features=25, out_features=outputs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), self.channels, 70, 320)\n",
    "        input = self.convLayers(input)\n",
    "        input = input.view(input.size(0), -1)\n",
    "        output = self.FC(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def accuracy(self, predictions, target):\n",
    "        totalCorrect = 0\n",
    "        for i in range(len(predictions)):\n",
    "            values, indices = torch.max(predictions[i], 0)\n",
    "            if indices == target[i]:\n",
    "                totalCorrect += 1\n",
    "\n",
    "        return (totalCorrect/len(target)) * 100\n",
    "\n",
    "    def fit(self, device, epochs, optimizer, criterion):\n",
    "        self.train()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        trainLoss = 0\n",
    "        iter_no = 0\n",
    "\n",
    "        validationAccuracy = []\n",
    "        trainAccuracy = []\n",
    "\n",
    "\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "\n",
    "            for iBatch, sampledBatch in enumerate(self.dataloader):\n",
    "\n",
    "                images = sampledBatch['image'].to(device).float()\n",
    "                controls = sampledBatch['control'].to(device).long()\n",
    "                controls = torch.flatten(controls)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predictions = self(images)\n",
    "                # print(\"Predictions\", predictions)\n",
    "                loss = criterion(predictions, controls)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tAccuracy = self.accuracy(predictions, controls)\n",
    "                print(\"[%d, %d] Loss:\" %(epoch, iBatch), loss)\n",
    "                print(\"Accuracy\", tAccuracy)\n",
    "\n",
    "                trainAccuracy.append(tAccuracy)\n",
    "\n",
    "\n",
    "                iter_no += 1\n",
    "                if iter_no % self.report_period == 0:\n",
    "                    self.writer.add_scalar(\"Loss\", loss.item(), iter_no)\n",
    "                    print(\"saved to tensorboard\")\n",
    "                    if self.channels < 3:\n",
    "                        self.save(epoch, \"snapshots/NormGray_{:.3f}_model.pt\".format(loss.item()))\n",
    "                    else:\n",
    "                        self.save(epoch, \"snapshots/Norm_{:.3f}_model.pt\".format(loss.item()))\n",
    "\n",
    "\n",
    "    def validationTest(self, device, dataset, single_batch=False):\n",
    "        self.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i_batch, sampled_batch in enumerate(dataset.validloader):\n",
    "            images = sampled_batch['image'].to(device).float()\n",
    "            controls = sampled_batch['control'].to(device).long()\n",
    "            controls = torch.flatten(controls)\n",
    "            prediction = self(images)\n",
    "\n",
    "            accuracy = self.accuracy(prediction, controls)\n",
    "            print(\"Validation Accuracy [i_batch=%d]\" %i_batch, accuracy)\n",
    "            if single_batch:\n",
    "                return accuracy\n",
    "        return (total, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-679f43d58ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCustomDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlsDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CustomDataset'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CustomDataset'",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from CustomDataset import ControlsDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "#     dataset = ControlsDataset(1, img_folder='../data/cropped/', csv_path='../data/cropped/data.csv')\n",
    "#     dataset.make_dataloaders()\n",
    "\n",
    "model = ClassConvNet(3, 14).to(device)\n",
    "summary(model, (3, 220, 400))\n",
    "\n",
    "'''\n",
    "epochs = 30\n",
    "report_period = 10\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i_batch, sampled_batch in tqdm_notebook(enumerate(dataset.dataloader),\n",
    "                                                   total=len(dataset.dataloader)):\n",
    "    model.train()\n",
    "    #inputs and forward pass\n",
    "    images = sampled_batch['image'].to(self.device).float()\n",
    "    controls = sampled_batch['control'].to(self.device).float()\n",
    "    controls = torch.flatten(controls)\n",
    "\n",
    "    #backwards pass\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(images)\n",
    "    prediction = torch.flatten(prediction)\n",
    "\n",
    "    #calculate loss\n",
    "    loss = self.criterion(prediction, controls)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}