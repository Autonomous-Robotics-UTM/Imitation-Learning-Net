{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1a81a8d1125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Ignore warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Models'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Models'",
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "import math\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNoise(object):\n",
    "    def __init__(self):\n",
    "        self.sigma = 0.02\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        noise = np.random.normal(0, self.sigma, image.size)\n",
    "        noise = noise.reshape(image.shape)\n",
    "        \n",
    "        out = image + noise\n",
    "        out = out.clip(min=0, max=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Labels():\n",
    "    def __init__(self,path):\n",
    "        self.dataframe = pd.read_csv(path)\n",
    "        self.transform = LabelTransform(self)\n",
    "        self.override_params = True\n",
    "        #categorical attributes\n",
    "        self.maximum = 1.05\n",
    "        self.minimum = -1.05\n",
    "        #directional attributes\n",
    "        self.directions = {\"left\":[[-1.05,0]],\"straight\":[[-0.01,0.01]],\"right\":[[0,1.05]]}\n",
    "        self.infotype = \"Angle\"\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataframe.iloc[index][self.infotype]\n",
    "    \n",
    "    def histogram(self):\n",
    "        return self.dataframe[self.infotype].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LabelTransform():\n",
    "    def __init__(self,labels):\n",
    "        self.labels = labels.dataframe\n",
    "        \n",
    "    def column_rule(self,column_name, function):\n",
    "        self.labels[column_name] = self.labels.apply(lambda x: function(x.Angle), axis=1)\n",
    "        \n",
    "    def categorize(self, maximum, minimum, num_categories):\n",
    "        def func(angle):\n",
    "            if angle == maximum:\n",
    "                return num_categories - 1\n",
    "            scale = num_categories/(maximum-minimum)\n",
    "            return math.floor(scale*(angle-minimum))\n",
    "        \n",
    "        #apply the categorization to the column\n",
    "        self.column_rule(\"Category\",func)\n",
    "        \n",
    "        #return the categories created\n",
    "        num_range = np.linspace(minimum,maximum,num_categories+1)\n",
    "        categories = [[round(num_range[i],3), round(num_range[i+1],3)] for i in range(len(num_range)-1)]\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    def directionalize(self,directions):\n",
    "        def direction(angle):\n",
    "            for key in directions:\n",
    "                for interval in directions[key]:\n",
    "                    start,end = interval\n",
    "                    if start < angle and end > angle:\n",
    "                        return key\n",
    "        self.labels['Direction'] = self.labels.apply(lambda x: direction(x.Angle), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Images():\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self.transform = ImageTransform()\n",
    "        self.stack_size = 1\n",
    "        self.grayscale = False\n",
    "        \n",
    "    def image_filename(self,path, number):\n",
    "        return \"{0}{number:06}.jpg\".format(path,number=number)\n",
    "        \n",
    "    def get_stack(self,index,stack_size):\n",
    "        img_filenames = [self.image_filename(self.path,i) \n",
    "                         for i in range(index, index+stack_size)]\n",
    "        images = np.array([io.imread(img_filename).transpose((2,0,1)) for img_filename in img_filenames])\n",
    "        images = self.transform.apply(images)/255\n",
    "        if not self.grayscale:\n",
    "            images = np.concatenate(images, axis=0)\n",
    "        return images\n",
    "    \n",
    "    def show(self,stack):\n",
    "        stack = stack.squeeze()\n",
    "        if self.grayscale:\n",
    "            f, ax = plt.subplots(stack_size, 1, figsize=(1*self.stack_size,25))\n",
    "            ax.imshow(stack,cmap='gray')\n",
    "            \n",
    "        else:\n",
    "            f, ax = plt.subplots(stack_size, 3, figsize=(3*self.stack_size,25))\n",
    "            ax = ax.reshape((self.stack_size,3))\n",
    "            for k in range(3*self.stack_size):\n",
    "                i,j = k//3, k % 3\n",
    "                ax[i,j].imshow(stack[k],cmap='gray')\n",
    "                \n",
    "        \n",
    "            \n",
    "    def set_grayscale(self, switch):\n",
    "        if self.grayscale != switch:\n",
    "            self.grayscale = switch\n",
    "            if switch:\n",
    "                self.transform.add(\"grayscale\")\n",
    "            else:\n",
    "                self.transform.remove(\"grayscale\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self):\n",
    "        self.transformations = []\n",
    "        \n",
    "    def apply(self,images):\n",
    "        for transformation in self.transformations:\n",
    "            function = getattr(self,transformation)\n",
    "            images = function(images)\n",
    "        return images\n",
    "    \n",
    "    def add(self,name):\n",
    "        self.transformations.append(name)\n",
    "        \n",
    "    def remove(self,name):\n",
    "        if name in self.transformations:\n",
    "            self.transformations.remove(name)\n",
    "    \n",
    "    def grayscale(self,images):\n",
    "        if images.shape[1] != 3:\n",
    "            return images\n",
    "        r, g, b = images[:,0,:,:], images[:,1,:,:], images[:,2,:,:]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ControlsDataset(Dataset):\n",
    "    \"\"\"Dataset that maps camera images into steering angle\"\"\"\n",
    "    def __init__(self,stack_size = 1 ,img_folder = '../data/original/', csv_path='../data/original/data.csv'):\n",
    "        self.stack_size = stack_size\n",
    "        self.images = Images(img_folder)\n",
    "        self.labels = Labels(csv_path)\n",
    "        self.transform = RandomNoise()\n",
    "\n",
    "    def make_dataloaders(self,train=0.8,test=0.2):\n",
    "        \n",
    "        indices = list(range(len(self)))\n",
    "        split = int(np.floor(test * len(self)))\n",
    "\n",
    "        # spliting the dataset\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        # Creating PT data samplers and loaders:\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        # Training data loader # NOTE had to remove shuffle\n",
    "        self.dataloader = DataLoader(self, \n",
    "                                     batch_size = 20,\n",
    "                                     num_workers = 0, \n",
    "                                     sampler=train_sampler)\n",
    "\n",
    "        # Validation data loader # NOTE had to remove shuffle\n",
    "        self.validloader = DataLoader(self, \n",
    "                                      batch_size = 20, \n",
    "                                      num_workers = 0, \n",
    "                                      sampler=valid_sampler)\n",
    "\n",
    "        print(\"Total training stacks\", len(self.dataloader))\n",
    "        print(\"Total validation stacks\",len(self.validloader))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels) - self.stack_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #get a stack of images\n",
    "        image_stack = self.images.get_stack(idx,self.stack_size)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_stack = self.transform(image_stack)\n",
    "        \n",
    "        # use the latest image as the control\n",
    "        label = self.labels[idx+self.stack_size]\n",
    "        label = np.array([label])\n",
    "        \n",
    "#         label = self.labels.dataframe['Category'][idx + self.stack_size]\n",
    "#         label = np.array([label])\n",
    "        #combine stack and label together\n",
    "        sample = {'image': image_stack, \n",
    "                  'control': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not useful\n",
    "class SampledDataset(ControlsDataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.unique = {}\n",
    "        \n",
    "    def categorical_median_sample(self):\n",
    "        import statistics\n",
    "        for element in enumerate(self.labels):\n",
    "            num, category = element\n",
    "            if category not in self.unique:\n",
    "                self.unique[category] = [num]\n",
    "            else:\n",
    "                self.unique[category].append(num)\n",
    "        \n",
    "        for key in self.unique:\n",
    "            print(\"cat: {}, count: {}\".format(key,len(self.unique[key])))\n",
    "            \n",
    "        lengths = [len(self.unique[key]) for key in self.unique]\n",
    "        print(statistics.median(lengths))\n",
    "        \n",
    "    def frame_rate(self, frame_rate):\n",
    "        print(self.labels.dataframe.shape)\n",
    "        newDataFrame = self.labels.dataframe.iloc[::frame_rate,:]\n",
    "        print(newDataFrame.shape)\n",
    "        \n",
    "        self.labels.dataframe = newDataFrame        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training stacks 441\n",
      "Total validation stacks 111\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stack_size = 1\n",
    "    dataset = ControlsDataset(stack_size)\n",
    "    dataset.make_dataloaders()\n",
    "    dataloader = dataset.dataloader\n",
    "    \n",
    "    \n",
    "    for i_batch, sampled_batch in enumerate(dataloader):\n",
    "        images = sampled_batch['image'].float()\n",
    "        controls = sampled_batch['control'].float()\n",
    "        \n",
    "        image = images[0,:,:,:]\n",
    "        image = np.transpose(image, (1,2,0))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}