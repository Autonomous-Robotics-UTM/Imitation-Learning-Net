{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CustomDataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from CustomDataset import ControlsDataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training stacks 138\n",
      "Total validation stacks 35\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = ControlsDataset()\n",
    "    #dataloader = DataLoader(dataset, batch_size = 256, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units after conv 1008\n",
      "conv parameters:  24896\n",
      "fc parameters:  25301\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,outputs,image_shape):\n",
    "        super(ConvNet, self).__init__()\n",
    "        img_size = list(image_shape)\n",
    "        img_size = torch.Size([1] + img_size)\n",
    "        empty = torch.zeros(img_size)\n",
    "        # Conv2d(in_channels, out_channels, kernelSize, strides)\n",
    "        \n",
    "        channels1,channels2,channels3 = 16,32,64\n",
    "        kernel1, kernel2, kernel3 = 11, 5, 3\n",
    "        padding1, padding2, padding3 = (kernel1-1)//2,(kernel2-1)//2,(kernel3-1)//2\n",
    "        stride1, stride2, stride3 = 2,2,1\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(image_shape[0], channels1, kernel1, stride1, padding1),\n",
    "                                  nn.BatchNorm2d(channels1),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(channels1, channels2, kernel2, stride2, padding2),\n",
    "                                  nn.BatchNorm2d(channels2),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(channels2, channels3, kernel3, stride3, padding3),\n",
    "                                  nn.BatchNorm2d(channels3),\n",
    "                                  nn.Tanh())\n",
    "        \n",
    "        out = self.conv1(empty)\n",
    "        out = self.conv2(out)\n",
    "        units = self.conv3(out).numel()\n",
    "        \n",
    "        print(\"units after conv\", units)\n",
    "        self.fc = nn.Sequential(nn.Linear(units, units//40),\n",
    "                                nn.BatchNorm1d(units//40),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(units//40, outputs)) # <-- Returning predictions over classes\n",
    "        \n",
    "        print(\"conv parameters: \", sum(p.numel() for p in self.conv1.parameters())+\n",
    "                                   sum(p.numel() for p in self.conv2.parameters())+\n",
    "                                   sum(p.numel() for p in self.conv3.parameters()))\n",
    "        print(\"fc parameters: \",sum(p.numel() for p in self.fc.parameters()))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x: batch, channel, height, width\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.reshape((batch_size,-1))\n",
    "        out = self.fc(out)\n",
    "        #print(out)\n",
    "        return out\n",
    "        \n",
    "    def load_weights(self,path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.start_epoch = checkpoint['epoch']\n",
    "        \n",
    "    def save_weights(self,optimizer,epoch,path):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, \n",
    "            path)\n",
    "       \n",
    "    def current_snapshot_name():\n",
    "        from time import gmtime, strftime\n",
    "        import socket\n",
    "\n",
    "        hostname = socket.gethostname()\n",
    "\n",
    "        date = strftime(\"%b%d_\", gmtime())\n",
    "        clock = strftime(\"%X\", gmtime())\n",
    "        now = clock.split(\":\")\n",
    "        now = date+'-'.join(now)\n",
    "\n",
    "        name = now+\"_\"+hostname\n",
    "        return name\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    net = ConvNet(3, 1, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([64, 3, 480, 640])\n",
      "output torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i, batch in enumerate(dataset.dataloader):\n",
    "        if i > 0:\n",
    "            break\n",
    "\n",
    "        imgs = batch['image'].float()\n",
    "        print(\"input\", imgs.shape)\n",
    "        out = net(imgs)\n",
    "        print(\"output\", out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
